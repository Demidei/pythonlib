{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1\n",
    "Импортируйте библиотеки pandas и numpy.\n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn..\n",
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью\n",
    "функции train_test_split так, чтобы размер тестовой выборки\n",
    "составлял 30% от всех данных, при этом аргумент random state должен быть равен 42.\n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля\n",
    "sklearn.linear_model.\n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на\n",
    "тестовых.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(\"BostonHousing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
       "       'ptratio', 'b', 'lstat', 'medv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data, columns=['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
    "       'ptratio', 'b', 'lstat',])\n",
    "y = pd.DataFrame(data, columns=[\"medv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio       b  lstat  medv  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 1)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "y_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>23.6</td>\n",
       "      <td>28.648960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>32.4</td>\n",
       "      <td>36.495014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>13.6</td>\n",
       "      <td>15.411193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22.8</td>\n",
       "      <td>25.403213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>16.1</td>\n",
       "      <td>18.855280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>20.0</td>\n",
       "      <td>23.146689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>17.8</td>\n",
       "      <td>17.392124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>14.0</td>\n",
       "      <td>14.078599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>19.6</td>\n",
       "      <td>23.036927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>16.8</td>\n",
       "      <td>20.599433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test     y_pred\n",
       "173    23.6  28.648960\n",
       "274    32.4  36.495014\n",
       "491    13.6  15.411193\n",
       "72     22.8  25.403213\n",
       "452    16.1  18.855280\n",
       "76     20.0  23.146689\n",
       "316    17.8  17.392124\n",
       "140    14.0  14.078599\n",
       "471    19.6  23.036927\n",
       "500    16.8  20.599433"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_test = pd.DataFrame({\n",
    "    \"y_test\": y_test[\"medv\"],\n",
    "    \"y_pred\": y_pred.flatten(),\n",
    "})\n",
    "\n",
    "check_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2\n",
    "Создайте модель под названием model с помощью класса RandomForestRegressor из модуля\n",
    "sklearn.ensemble.\n",
    "Сделайте агрумент n_estimators равным 1000,\n",
    "max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "чтобы получить из датафрейма одномерный массив Numpy,\n",
    "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно\n",
    "применение массивов вместо датафрейма.\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из\n",
    "предыдущего задания.\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=1000,max_depth=12, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = pd.DataFrame(data, columns=['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'tax',\n",
    "       'ptratio', 'b', 'lstat', 'medv'])\n",
    "y2 = pd.DataFrame(data, columns=[\"rad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dimagv\\AppData\\Local\\Temp\\ipykernel_19468\\2113787560.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X2_train, y2_train)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=12, n_estimators=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=12, n_estimators=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=12, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_pred = model.predict(X2_test)\n",
    "y2_pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_pred2\n",
       "173       5        5\n",
       "274       4        4\n",
       "491       4        4\n",
       "72        4        4\n",
       "452      24       24\n",
       "76        5        4\n",
       "316       4        4\n",
       "140       4        4\n",
       "471      24       24\n",
       "500       6        6"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_test = pd.DataFrame({\n",
    "    \"y_test\": y2_test[\"rad\"],\n",
    "    \"y_pred2\": y2_pred,\n",
    "})\n",
    "\n",
    "check_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9949670624034594"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "r2_rfr = r2_score(y2_test, y2_pred)\n",
    "r2_rfr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7112260057484948"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_lr = r2_score(y_test, y_pred)\n",
    "r2_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Задание 3\n",
    "Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances_.\n",
    "С помощью этого атрибута найдите сумму всех показателей важности,\n",
    "установите, какие два признака показывают наибольшую важность.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot  as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Global Feature Importance - Built-in Method')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_importances = pd.Series(model.feature_importances_, index=X2_train.columns)\n",
    "global_importances.sort_values(ascending=True, inplace=True)\n",
    "global_importances.plot.barh(color='green')\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Global Feature Importance - Built-in Method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_importances.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Задание 4\n",
    "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию\n",
    "по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать\n",
    "задачу классификации - будем определять,какие из транзакции по кредитной карте являются\n",
    "мошенническими.Данный датасет сильно несбалансирован (так как случаи мошенничества\n",
    "относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать\n",
    "лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка\n",
    "несбалансирована. Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет\n",
    "ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы\n",
    "датафрейма:\n",
    "pd.options.display.max_columns = 100.\n",
    "© geekbrains.ru 1\n",
    "Просмотрите первые 10 строк датафрейма df.\n",
    "Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "Создайте объект Series под названием y из столбца Class.\n",
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split,\n",
    "используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "Просмотрите информацию о их форме.\n",
    "Для поиска по сетке параметров задайте такие параметры:\n",
    "parameters = [{'n_estimators': [10, 15],\n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]\n",
    "Создайте модель GridSearchCV со следующими аргументами:\n",
    "estimator=RandomForestClassifier(random_state=100),\n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3.\n",
    "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "Предскажите вероятности классов с помощью полученной модели и метода predict_proba.\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и\n",
    "запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных,\n",
    "используя в качестве аргументов массивы y_test и y_pred_proba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"creditcard.csv.zip\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      V1          V2          V3         V4         V5         V6         V7          V8          V9         V10        V11        V12        V13        V14        V15        V16        V17        V18        V19        V20        V21         V22        V23        V24        V25        V26        V27        V28        Amount  Class\n",
       "163152.0  -1.196037    1.585949    2.883976   3.378471   1.511706   3.717077   0.585362   -0.156001    0.122648   4.217934   1.385525  -0.709405  -0.256168  -1.564352   1.693218  -0.785210  -0.228008  -0.412833   0.234834   1.375790  -0.370294    0.524395  -0.355170  -0.869790  -0.133198   0.327804  -0.035702  -0.858197  7.56    0        0.000063\n",
       "          -1.203617    1.574009    2.889277   3.381404   1.538663   3.698747   0.560211   -0.150911    0.124136   4.220998   1.384569  -0.706897  -0.256274  -1.562583   1.692915  -0.787338  -0.226776  -0.412354   0.234322   1.385597  -0.366727    0.522223  -0.357329  -0.870174  -0.134166   0.327019  -0.042648  -0.855262  1.51    0        0.000063\n",
       "43153.0   -2.086016    2.203265    1.654339   2.941050  -1.683045   0.529728  -1.352162    1.793449   -0.723686   0.600365  -0.982212  -0.551636  -1.337000   0.834403   1.251862   0.033455   1.067978   0.160510   0.213087   0.079002   0.216444    0.567241  -0.035345   0.370201   0.157378   0.440341   0.210230   0.090558  0.76    0        0.000032\n",
       "170731.0   2.033492    0.766969   -2.107555   3.631952   1.348594  -0.499907   0.945159   -0.286392   -1.370581   1.653073  -1.600434  -1.510901  -2.143280   1.189850  -0.875588   0.175808  -0.419433  -0.464717  -1.414528  -0.430560   0.241894    0.658545  -0.102644   0.580535   0.643637   0.347240  -0.116618  -0.078601  0.76    0        0.000032\n",
       "68207.0   -13.192671   12.785971  -9.906650   3.320337  -4.801176   5.760059  -18.750889  -37.353443  -0.391540  -5.052502   4.406806  -4.610756  -1.909488  -9.072711  -0.226074  -6.211557  -6.248145  -3.149247   0.051576  -3.493050   27.202839  -8.887017   5.303607  -0.639435   0.263203  -0.108877   1.269566   0.939407  1.00    1        0.000021\n",
       "                                                                                                                                                                                                                                                                                                                                                      ...   \n",
       "65149.0   -0.608037    0.277482    2.333740   0.713876  -0.686327   0.424502   0.158410    0.277078    0.005665  -0.574444  -0.383596   0.063757   0.435809  -0.294166   1.561564   0.430549  -0.512260   0.321857  -1.089111   0.192164   0.425425    1.077523   0.095700   0.080007  -0.087784  -0.253436   0.077868   0.055774  115.98  0        0.000004\n",
       "           0.890428   -0.914533    0.916273   0.533497  -1.417793  -0.283902  -0.520284    0.002223   -1.050330   0.827726   1.336306   0.961705   0.778165   0.101997   0.352339  -0.892199  -0.538873   1.792922  -1.092627  -0.119284  -0.239564   -0.634749  -0.018377   0.482486   0.102384  -0.559266   0.040121   0.067240  192.05  0        0.000004\n",
       "65150.0   -0.819167    1.289630    1.155617  -0.356589   0.742668  -1.179886   1.114827   -0.105033   -1.169136  -1.218791   1.841286   0.558376   0.081792  -1.028918  -0.400824   0.722658   0.402985   0.613975  -0.605494  -0.014715  -0.011025   -0.125263  -0.385443   0.449483   0.536560   0.252429  -0.020876   0.072608  0.76    0        0.000004\n",
       "          -0.283939    1.355339    0.553398   0.255501   0.561040  -1.338352   1.056880   -0.229176   -0.738105  -1.157676   0.000759  -0.543236  -0.313497  -1.370815   0.770587   0.452886   1.064176   0.458320  -0.199074  -0.019922  -0.076192   -0.211969  -0.256209   0.259185   0.096589   0.327896   0.021232   0.083294  0.76    0        0.000004\n",
       "172792.0  -0.533413   -0.189733    0.703337  -0.506271  -0.012546  -0.649617   1.577006   -0.414650    0.486180  -0.915427  -1.040458  -0.031513  -0.188093  -0.084316   0.041333  -0.302620  -0.660377   0.167430  -0.256117   0.382948   0.261057    0.643078   0.376777   0.008797  -0.473649  -0.818267  -0.002415   0.013649  217.00  0        0.000004\n",
       "Length: 283726, dtype: float64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V20       V21  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ...  0.251412 -0.018307   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.524980  0.247998   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.208038 -0.108300   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ...  0.408542 -0.009431   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  1.475829  0.213454   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.059616  0.214205   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.001396  0.232045   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.127434  0.265245   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.382948  0.261057   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
       "284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
       "284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
       "284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
       "284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
       "\n",
       "        Amount  \n",
       "0       149.62  \n",
       "1         2.69  \n",
       "2       378.66  \n",
       "3       123.50  \n",
       "4        69.99  \n",
       "...        ...  \n",
       "284802    0.77  \n",
       "284803   24.79  \n",
       "284804   67.88  \n",
       "284805   10.00  \n",
       "284806  217.00  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Class', axis= 1 )\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=pd.Series(df['Class'])\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199364, 30)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 30)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199364,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443,)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [10, 15],\n",
    "    'max_features': np.arange(3, 5),\n",
    "    'max_depth': np.arange(4, 7),\n",
    "}\n",
    "\n",
    "model2 = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=100),\n",
    "    param_grid=parameters,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=100),\n",
       "             param_grid={&#x27;max_depth&#x27;: array([4, 5, 6]),\n",
       "                         &#x27;max_features&#x27;: array([3, 4]),\n",
       "                         &#x27;n_estimators&#x27;: [10, 15]},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=100),\n",
       "             param_grid={&#x27;max_depth&#x27;: array([4, 5, 6]),\n",
       "                         &#x27;max_features&#x27;: array([3, 4]),\n",
       "                         &#x27;n_estimators&#x27;: [10, 15]},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=100)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=100)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=100),\n",
       "             param_grid={'max_depth': array([4, 5, 6]),\n",
       "                         'max_features': array([3, 4]),\n",
       "                         'n_estimators': [10, 15]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseSearchCV.predict_proba of GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=100),\n",
       "             param_grid={'max_depth': array([4, 5, 6]),\n",
       "                         'max_features': array([3, 4]),\n",
       "                         'n_estimators': [10, 15]},\n",
       "             scoring='roc_auc')>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0012883 , 0.00026266, 0.00029286, ..., 0.00028215, 0.00033699,\n",
       "       0.00028215])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba=model2.predict_proba(X).transpose()[1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807,)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba=y_pred_proba[:85443]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443,)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48437065795498296"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
